# Faith Benchmark Configuration
# Copy this file to .env and fill in your actual API keys and preferences

# =============================================================================
# API KEYS (Required - OpenRouter API key for unified access to multiple models)
# =============================================================================

# OpenRouter API Key
# Get your API key from: https://openrouter.ai/keys
# This single key provides access to OpenAI, Anthropic, Google, and other models
OPENROUTER_API_KEY=your_openrouter_api_key_here

# =============================================================================
# MODEL CONFIGURATION (Optional - uses sensible defaults)
# =============================================================================

# OpenRouter Model Configuration
# Model to use (can be overridden by --model command line argument)
# Examples: openai/gpt-4, anthropic/claude-3-sonnet, google/gemini-pro
OPENROUTER_MODEL=openai/gpt-4
OPENROUTER_TEMPERATURE=0.0
OPENROUTER_MAX_TOKENS=10

# =============================================================================
# TESTING CONFIGURATION (Optional - uses sensible defaults)
# =============================================================================

# Checkpoint interval (save progress every N questions)
CHECKPOINT_INTERVAL=10

# Output directory for results and checkpoints
OUTPUT_DIRECTORY=results

# Delay between questions in seconds (to avoid rate limiting)
DELAY_BETWEEN_QUESTIONS=1.0

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO
